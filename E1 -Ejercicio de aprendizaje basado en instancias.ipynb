{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje basado en instancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador *nokNN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el artículo [1] se propone una alternativa al procedimiento de clasificación *kNN* que no se vea sesgada por la elección del número de vecinos ($k$). La idea consiste en agregar los vecindarios obtenidos por el procedimiento estándar del algoritmo *kNN*, para todos los valores de $k$ desde 1 hasta un valor máximo preestablecido ($T_k$); y realizar la clasificación a partir de estos vecindarios. La descripción detallada del procedimiento es la siguiente:\n",
    "\n",
    "Supongamos que $X$ es el conjunto de entrenamiento e $Y$, la clasificación asociada, definimos\n",
    "* $N = |X|$, el número de elementos de $X$\n",
    "* $N_c = |\\{x \\in X, Y(x) = c\\}|$, el número de elementos de $X$ con valor de clasificación $c$\n",
    "* $M_c = (2^N-1) \\cdot N_c/N$\n",
    "\n",
    "Dado el valor $T_k$ preestablecido, se consideran los conjuntos $A_k \\subseteq X$, para todo $k = 1,..,T_k$. Cada $A_k$ es el vecindario formado por los $k$ vecinos más cercanos a un nuevo valor $x$ dentro de $X$.\n",
    "\n",
    "Para cada $A_k$ se define su *función de masa* para la clase $c$ de la siguiente forma:\n",
    "\n",
    "$$m_c(A_k) = \\frac{P(c|A_k)}{M_c} = \\frac{P(A_k,c)}{P(A_k)\\cdot M_c} = \n",
    "             \\frac{|\\{x \\in A_k, Y(x) = c\\}|}{k\\cdot M_c}$$\n",
    "\n",
    "Por completitud se supone la existencia de otro conjunto de datos $A \\subseteq X$ tal que $m_c(A)$ compense los valores de $m_c(A_k)$ para que la suma total sea 1, tal y como se indica en [1].\n",
    "\n",
    "A continuación se define una función de probabilidad basada en la *función de masa*\n",
    "\n",
    "$$G_c(x) = \\sum_{B\\subseteq X} m_c(B) \\cdot \\frac{|\\{x\\}\\cap B|}{|B|}$$\n",
    "\n",
    "Suponiendo además que el elemento $x$ está en cada uno de los vecindarios $A_h$, pero no está en el conjunto $A$ y dado que el valor de la *función de masa* de cualquier conjunto distinto de $A_h$ y $A$ es 0, se simplifica el cálculo de $G_c(x)$ de la siguiente manera:\n",
    "\n",
    "$$G_c(x) = \\sum_{k=1}^{T_k} m_c(A_k) \\cdot \\frac{|\\{x\\}\\cap A_k|}{|A_k|} = \n",
    "           \\sum_{k=1}^{T_k} m_c(A_k) \\cdot \\frac{1}{k} =\n",
    "           \\sum_{k=1}^{T_k} \\frac{|\\{x \\in A_k, Y(x) = c\\}|}{k\\cdot M_c} \\cdot \\frac{1}{k} =\n",
    "           \\sum_{k=1}^{T_k} \\frac{|\\{x \\in A_k, Y(x) = c\\}|}{k^2\\cdot M_c}$$\n",
    "           \n",
    "Finalmente, el valor de clasificación de $x$ será la clase $c$ para la que el valor $G_c(x)$ sea máximo.\n",
    "\n",
    "[1] Wang, H., Düntsch, I., Gediga, G., Guo, G. (2005). Nearest Neighbours without k . In: Monitoring, Security, and Rescue Techniques in Multiagent Systems. Advances in Soft Computing, vol 28. Springer, Berlin, Heidelberg. https://doi.org/10.1007/3-540-32370-8_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ejercicio consiste en:\n",
    "\n",
    "* Definir la función `kNNBestKScore(T_k,X_train,y_train,X_test,y_test)` que, dado un valor máximo para el número de vecinos, `T_k`, un conjunto de entrenamiento y su clasificación, `X_train` e `y_train`, y un conjunto de prueba y su clasificación, `X_test` e `y_test`, devuelva el par `(maxK,maxS)` formado por el valor del número de vecinos, `maxK`, entre 1 y `T_k` (incluido) que maximiza el rendimiento en el conjunto de prueba `X_test` del clasificador *kNN* construido con el conjunto de entrenamiento `X_train`, siendo `maxS` dicho rendimiento.\n",
    "* Definir la función `nokNNClassifierPredict(T_k,X_train,y_train,X)` que, dado un valor máximo para el número de vecinos, `T_k`, un conjunto de entrenamiento y su clasificación, `X_train` e `y_train`, y un array de valores nuevos, `X`, devuelve el array de clasificaciones asignadas a los valores del array `X` por el clasificador *nokNN* descrito en el primer apartado de este enunciado.\n",
    "* Definir la función `nokNNClassifierScore(T_k,X_train,y_train,X_test,y_test)` que, dado un valor máximo para el número de vecinos, `T_k`, un conjunto de entrenamiento y su clasificación, `X_train` e `y_train`, y un conjunto de prueba y su clasificación, `X_test` e `y_test`, devuelve el rendimiento en el conjunto de prueba `X_test` del clasificador *nokNN* construido con el conjunto de entrenamiento `X_train`.\n",
    "* Evaluar las funciones `kNNBestKScore` y `nokNNClassifierScore` sobre los conjuntos de datos *Iris*, *Wine* y *Breast Cancer* de *Scikit-Learn*.\n",
    "\n",
    "El **desarrollo tiene que estar razonado**, indicando en cada apartado qué se está haciendo, **demostrando así el conocimiento adquirido en este módulo**. ¿Qué conclusiones puedes sacar sobre el clasificador *nokNN* comparado con el *kNN*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui simplemente cargamos los conjuntos de datos en 3 variables: iris, wine y cancer\n",
    "\n",
    "from sklearn.datasets import load_iris,load_wine,load_breast_cancer\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "wine= load_wine()\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos el conjunto Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque para el apartado de la comparacion usare los 3 conjuntos,igualmente en cada apartado haré una llamada  y evaluraé el método para comprobar su correcto funcionamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, X_names, y_names = \\\n",
    "    iris.data, iris.target, iris.feature_names, iris.target_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "  train_test_split(X_data,y_data,test_size = 0.33,\n",
    "                   random_state=4861,stratify=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 1  kNNBestKScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la función `kNNBestKScore(T_k,X_train,y_train,X_test,y_test)` que, dado un valor máximo para el número de vecinos, `T_k`, un conjunto de entrenamiento y su clasificación, `X_train` e `y_train`, y un conjunto de prueba y su clasificación, `X_test` e `y_test`, devuelva el par `(maxK,maxS)` formado por el valor del número de vecinos, `maxK`, entre 1 y `T_k` (incluido) que maximiza el rendimiento en el conjunto de prueba `X_test` del clasificador *kNN* construido con el conjunto de entrenamiento `X_train`, siendo `maxS` dicho rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado tengo que calcular el valor máximo para el conjunto de vecinos, para eso me he definido dos variables maxK y maxS que serán el rendimiento y el nº de vecinos que maximiza este, después recorro los valores desde 1 hasta T_k siendo este el nº de vecinos máximo, creo después una instancia con KNeighborsClassifier para el número de vecinos de la iteración y entreno la instancia con el conjunto de entrenamiento.\n",
    "\n",
    "Finalmente calculo el rendimiento con el score y lo comparo al almacenado, si es mayor guardo el score y el valor de la iteración (i) como los nuevos máximos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T_k es el numero maximo de vecinos\n",
    "# Tengo que devolver maxK (vecinos que maximiza el rendimiento) y maxS (el rendimiento más alto)\n",
    "def kNNBestKScore(T_k,X_train,y_train,X_test,y_test):\n",
    "    \n",
    "    #Declaro las variables del resultado inicializadas a 0\n",
    "    maxK=0;\n",
    "    maxS=0;\n",
    "    \n",
    "    #Recorro los valores desde 1 hasta el valor de T_k, que es el número máximo de vecinos\n",
    "    for i in range(1, T_k + 1):\n",
    "\n",
    "        # definimos el clasificador  para cada valor de i\n",
    "        knn1 = KNeighborsClassifier(n_neighbors=i,p=2)\n",
    "        \n",
    "        # entrenamos\n",
    "        knn1.fit(X_train,y_train)\n",
    "        \n",
    "        # calculamos el rendimiento para el conjunto de prueba\n",
    "        score = knn1.score(X_test,y_test)\n",
    "        \n",
    "        # comparamos, si es mejor lo guardamos en la variable\n",
    "        if(score > maxS):\n",
    "            maxS= score;\n",
    "            maxK=i;\n",
    "    \n",
    "    #Imprimimos por pantalla para dar mas resultado\n",
    "    print(\"El número de vecinos que maximiza el rendimiento es \" + str(maxK) + \" cuyo rendimiento es \" + str(maxS))\n",
    "    \n",
    "    return maxK,maxS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de vecinos que maximiza el rendimiento es 5 cuyo rendimiento es 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 0.96)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNNBestKScore(5,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 2 nokNNClassifierPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la función `nokNNClassifierPredict(T_k,X_train,y_train,X)` que, dado un valor máximo para el número de vecinos, `T_k`, un conjunto de entrenamiento y su clasificación, `X_train` e `y_train`, y un array de valores nuevos, `X`, devuelve el array de clasificaciones asignadas a los valores del array `X` por el clasificador *nokNN* descrito en el primer apartado de este enunciado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta el enunciado de la primera parte, en este apartado lo que he hecho ha sido:\n",
    "\n",
    "* Primero antes de nada inicializo un array con los valores donde almacenaré las predicciones, además de calcular y almacenar el nº de elementos del conjunto en una variable N\n",
    "\n",
    "* Después recorro los elementos del conjunto X, en el que calcularemos las distancias\n",
    "\n",
    "* Itero sobre cada clase unica y sobre los vecindarios de 1 hasta T_k (incluido), en el que calculo los vecinos mas cercanos,pondero por la prob de la clase y almaceno la puntuación para esa clase\n",
    "\n",
    "* Finalmente me quedo la que tenga un valor máximo\n",
    "\n",
    "Referencias utilizadas en este apartado:\n",
    "\n",
    "* https://stackoverflow.com/questions/16680334/using-numpy-argsort-and-take-in-2d-arrays\n",
    "* https://stackoverflow.com/questions/7741878/how-to-apply-numpy-linalg-norm-to-each-row-of-a-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nokNNClassifierPredict(T_k, X_train, y_train, X):\n",
    "    # Inicializamos el array vacio de las futuras predicciones\n",
    "    y_pred = []\n",
    "    \n",
    "    # Calculo el número de elementos en el conjunto de entrenamiento\n",
    "    N = len(X_train)\n",
    "    \n",
    "    for x in X:\n",
    "        # defino una variable para almacenar G_c(x) para cada clase c\n",
    "        c_scores = {}\n",
    "\n",
    "        # Calculamos las distancias\n",
    "        distances = np.linalg.norm(X_train - x, axis=1)\n",
    "\n",
    "        # itero sobre cada clase unica del conjunto \n",
    "        for c in np.unique(y_train):\n",
    "            # calculamos los elementos del conjunto con el valor c\n",
    "            N_c = np.sum(y_train == c)\n",
    "            M_c = (2 * N - 1) * N_c / N\n",
    "            G_c_x = 0.0\n",
    "\n",
    "            # iteramos sobre cada vecindario\n",
    "            for k in range(1, T_k + 1):\n",
    "                \n",
    "                # calculamos los mas cercanos\n",
    "                nearest_neighbors_indices = np.argsort(distances)[:k]\n",
    "                neighbors_c = np.sum(y_train[nearest_neighbors_indices] == c)\n",
    "                # Ponderamos por la probabilidad de la clase\n",
    "                G_c_x += (neighbors_c / k) * M_c\n",
    "\n",
    "            # almacenamos la puntuacion para la clase c\n",
    "            c_scores[c] = G_c_x\n",
    "\n",
    "        # Nos quedamos con la clase con el valor máximo\n",
    "        y_pred.append(max(c_scores, key=c_scores.get))\n",
    "\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando ejecuto este método lo que me devuelve es un array con las clasificaciones del conjunto X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 1, 1, 2, 2, 1, 1, 2, 0, 1, 0, 1, 1, 2, 2, 0, 0, 2, 1,\n",
       "       1, 0, 0, 1, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 2, 0, 2,\n",
       "       2, 0, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nokNNClassifierPredict(5, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 3 nokNNClassifierScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la función `nokNNClassifierScore(T_k,X_train,y_train,X_test,y_test)` que, dado un valor máximo para el número de vecinos, `T_k`, un conjunto de entrenamiento y su clasificación, `X_train` e `y_train`, y un conjunto de prueba y su clasificación, `X_test` e `y_test`, devuelve el rendimiento en el conjunto de prueba `X_test` del clasificador *nokNN* construido con el conjunto de entrenamiento `X_train`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí lo que estoy haciendo es simplemente llamar al metodo que he creado en el apartado 2 nokNNClassifierPredict y el array con la clasificacion de los valores del conjunto  X_test(y_pred) lo comparo con la del array de y_test con la función accuracy_score obteniendo así el rendimiento(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nokNNClassifierScore(T_k, X_train, y_train, X_test, y_test):\n",
    "    # llamamos al metodo de noKNN y guardamos las predicciones en una variables\n",
    "    y_pred = nokNNClassifierPredict(T_k, X_train, y_train, X_test)\n",
    "    #Calculamos el rendimiento con la función accuracy_score \n",
    "    score = accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nokNNClassifierScore(5, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluar las funciones `kNNBestKScore` y `nokNNClassifierScore` sobre los conjuntos de datos *Iris*, *Wine* y *Breast Cancer* de *Scikit-Learn*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado voy a evaluar los 3 conjuntos uno a uno y viendo los rendimientos para el mismo conjunto del clasificador KNN y el noKNN que he realizado en el apartado 1 y 2 respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, X_names, y_names = \\\n",
    "    iris.data, iris.target, iris.feature_names, iris.target_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "  train_test_split(X_data,y_data,test_size = 0.33,\n",
    "                   random_state=4861,stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de vecinos que maximiza el rendimiento es 5 cuyo rendimiento es 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNNBestKScore(5,X_train,y_train,X_test,y_test)\n",
    "\n",
    "nokNNClassifierScore(5, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, X_names, y_names = \\\n",
    "    wine.data, wine.target, wine.feature_names, wine.target_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "  train_test_split(X_data,y_data,test_size = 0.33,\n",
    "                   random_state=4861,stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de vecinos que maximiza el rendimiento es 1 cuyo rendimiento es 0.7457627118644068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7627118644067796"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNNBestKScore(5,X_train,y_train,X_test,y_test)\n",
    "\n",
    "nokNNClassifierScore(5, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, X_names, y_names = \\\n",
    "    cancer.data, cancer.target, cancer.feature_names, cancer.target_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "  train_test_split(X_data,y_data,test_size = 0.33,\n",
    "                   random_state=4861,stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de vecinos que maximiza el rendimiento es 2 cuyo rendimiento es 0.9468085106382979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9308510638297872"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNNBestKScore(5,X_train,y_train,X_test,y_test)\n",
    "\n",
    "nokNNClassifierScore(5, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El rendimiento del noKNN es muy parecido en términos de rendimiento al KNN en los conjuntos de datos que hemos testado\n",
    "\n",
    "* El algoritmo noKNN no se ve tan afectado por la sensibilidad del parámetro K (infrajuste o sobreajuste) debido a que no está tan condicionada por el valor de K, ya que calcula múltiples valores de este y luego combina la información para la clasificación.\n",
    "\n",
    "* Para conjuntos de datos más estructurados el KNN debe ser mejor mientrás que para estructuras de datos no tan claras será mejor el noKNN ya que se adapta de manera más flexible a la estructura de datos\n",
    "\n",
    "* A nivel computacional noKNN debe ser más costoso ya que supone múltiples valores de k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
